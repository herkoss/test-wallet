# AI-Assisted Development Process

## Overview

During the development of this test assignment, I actively used AI assistants as
supporting tools to speed up understanding, implementation, and validation of
the requirements. The goal was not to delegate decision-making to AI, but to use
it as an accelerator for routine tasks, documentation analysis, and boilerplate
generation, while keeping all architectural and technical decisions under my
control.

The two primary AI tools used were **ChatGPT** and **Claude Code**, each serving
a distinct purpose in the workflow.

---

## ChatGPT Usage

ChatGPT was used mainly as a **research, clarification, and planning
assistant**.

### Primary Use Cases

- **Specification analysis** I used ChatGPT to break down the task description
  and requirements into clear, actionable technical steps.

- **Documentation exploration** ChatGPT helped navigate and summarize the Tether
  Wallet Development Kit (WDK) documentation, including:
  - Wallet creation and seed phrase handling
  - Balance retrieval
  - Transaction creation and fee estimation
  - Indexer API usage

- **Feature planning** Used for high-level discussions around:
  - Wallet UX flows (send / receive)
  - Error handling strategies
  - Best practices for mobile crypto wallets

- **Concept validation** I used ChatGPT to sanity-check ideas and approaches
  (for example, wallet switching, SDK abstraction layers, and transaction
  lifecycle handling).

### What ChatGPT Was _Not_ Used For

- Making final architectural decisions
- Writing production-ready business logic without review
- Debugging SDK-specific runtime issues blindly

All suggestions were manually reviewed and adapted to the real behavior of the
SDK and APIs.

---

## Claude Code Usage

Claude Code was used primarily as a **coding assistant**.

### Primary Use Cases

- **Generating code based on documentation** Claude was used to write initial
  implementations based on:
  - WDK documentation
  - Previously clarified specifications

- **Boilerplate and repetitive code** Helped accelerate:
  - Service layers
  - Data mapping
  - Basic UI scaffolding

- **Refactoring support** Assisted in improving readability and consistency of
  existing code after the core logic was validated.

### Human-in-the-Loop Approach

All code generated by Claude Code was:

- Manually reviewed
- Tested in the real application environment
- Modified to match actual SDK behavior and edge cases

This was especially important when dealing with:

- RPC node instability
- Indexer delays
- SDK error handling inconsistencies

---

## Debugging and Problem Solving

While AI tools helped with understanding and scaffolding, **all debugging was
performed manually** using:

- Runtime logs
- SDK-level inspection
- Incremental isolation of failing components

AI-generated suggestions were sometimes useful as hypotheses, but final fixes
required hands-on debugging and verification.

---

## Summary

AI tools were used as **assistive instruments**, not as autonomous agents.

They provided:

- Faster onboarding into unfamiliar SDKs
- Reduced time spent on repetitive tasks
- Better focus on problem-solving and architecture

Final responsibility for correctness, security, UX, and implementation decisions
remained entirely on the developer.

This approach reflects how AI tools can be effectively integrated into a
professional engineering workflow without replacing core engineering judgment.
